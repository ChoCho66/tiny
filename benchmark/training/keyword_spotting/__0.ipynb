{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conda 安裝 python 3.11 版本\n",
    "- conda install ipykernel\n",
    "- sudo apt update\n",
    "- sudo apt install ffmpeg\n",
    "- ffprobe -version\n",
    "- 把 keras_model.py 的 DepthwiseConv2D 裡的 kernel_regularizer 改成 depthwise_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub tensorflow[and-cuda] matplotlib tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 15:53:32.742095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733903612.758292  137400 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733903612.763105  137400 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 15:53:32.778811: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "We will download data to /home/kycho/data\n",
      "We will train for 36 epochs\n",
      "I0000 00:00:1733903614.545787  137400 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21471 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:0b:00.0, compute capability: 7.5\n",
      "Done getting data\n",
      "Starting with untrained model\n",
      "DS CNN model invoked\n",
      "\u001b[1mModel: \"functional\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ input_layer (\u001b[94mInputLayer\u001b[0m)        │ (\u001b[96mNone\u001b[0m, \u001b[32m49\u001b[0m, \u001b[32m10\u001b[0m, \u001b[32m1\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d (\u001b[94mConv2D\u001b[0m)                 │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │         \u001b[32m2,624\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization             │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation (\u001b[94mActivation\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout (\u001b[94mDropout\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ depthwise_conv2d                │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m640\u001b[0m │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_1           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_1 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │         \u001b[32m4,160\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_2           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_2 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ depthwise_conv2d_1              │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m640\u001b[0m │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_3           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_3 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │         \u001b[32m4,160\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_4           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_4 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ depthwise_conv2d_2              │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m640\u001b[0m │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_5           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_5 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │         \u001b[32m4,160\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_6           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_6 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ depthwise_conv2d_3              │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m640\u001b[0m │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_7           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_7 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2d_4 (\u001b[94mConv2D\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │         \u001b[32m4,160\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ batch_normalization_8           │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │           \u001b[32m256\u001b[0m │\n",
      "│ (\u001b[94mBatchNormalization\u001b[0m)            │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ activation_8 (\u001b[94mActivation\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dropout_1 (\u001b[94mDropout\u001b[0m)             │ (\u001b[96mNone\u001b[0m, \u001b[32m25\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m64\u001b[0m)      │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ average_pooling2d               │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)       │             \u001b[32m0\u001b[0m │\n",
      "│ (\u001b[94mAveragePooling2D\u001b[0m)              │                        │               │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ flatten (\u001b[94mFlatten\u001b[0m)               │ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m)             │             \u001b[32m0\u001b[0m │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)                   │ (\u001b[96mNone\u001b[0m, \u001b[32m12\u001b[0m)             │           \u001b[32m780\u001b[0m │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m24,908\u001b[0m (97.30 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m23,756\u001b[0m (92.80 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m1,152\u001b[0m (4.50 KB)\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 1/36\n",
      "2024-12-11 15:53:40.567478: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733903627.155280  137444 service.cc:148] XLA service 0x72e420003620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733903627.155319  137444 service.cc:156]   StreamExecutor device (0): Quadro RTX 6000, Compute Capability 7.5\n",
      "2024-12-11 15:53:47.270911: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733903627.776700  137444 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1733903631.394962  137444 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - loss: 1.2963 - sparse_categorical_accuracy: 0.6737 - val_loss: 0.5127 - val_sparse_categorical_accuracy: 0.8499 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 2/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.4543 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.3450 - val_sparse_categorical_accuracy: 0.8979 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 3/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.3508 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.9078 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 4/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.3080 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9190 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 5/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.9199 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9342 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 6/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2576 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9240 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 7/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2362 - sparse_categorical_accuracy: 0.9327 - val_loss: 0.2166 - val_sparse_categorical_accuracy: 0.9373 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 8/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2326 - sparse_categorical_accuracy: 0.9320 - val_loss: 0.2047 - val_sparse_categorical_accuracy: 0.9408 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 9/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2161 - sparse_categorical_accuracy: 0.9384 - val_loss: 0.1984 - val_sparse_categorical_accuracy: 0.9452 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 10/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2100 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.1895 - val_sparse_categorical_accuracy: 0.9460 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.2062 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.1919 - val_sparse_categorical_accuracy: 0.9460 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 12/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1974 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9462 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 13/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1842 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.1665 - val_sparse_categorical_accuracy: 0.9545 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 14/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9532 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 15/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1743 - sparse_categorical_accuracy: 0.9512 - val_loss: 0.1634 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 16/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1683 - sparse_categorical_accuracy: 0.9525 - val_loss: 0.1648 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 17/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1704 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.1610 - val_sparse_categorical_accuracy: 0.9562 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 18/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1621 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9552 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 19/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1586 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9574 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 20/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1627 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.1604 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9567 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.1613 - val_sparse_categorical_accuracy: 0.9546 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.1593 - val_sparse_categorical_accuracy: 0.9567 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1581 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.1577 - val_sparse_categorical_accuracy: 0.9565 - learning_rate: 1.0000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 25/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1505 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9569 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 26/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9578 - val_loss: 0.1572 - val_sparse_categorical_accuracy: 0.9559 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 27/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 0.9567 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 28/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1500 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9565 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 29/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.1574 - val_sparse_categorical_accuracy: 0.9566 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 30/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9566 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 31/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1492 - sparse_categorical_accuracy: 0.9587 - val_loss: 0.1555 - val_sparse_categorical_accuracy: 0.9567 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 32/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.1569 - val_sparse_categorical_accuracy: 0.9564 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 33/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9567 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 34/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1484 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1563 - val_sparse_categorical_accuracy: 0.9568 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 35/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.1466 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.1568 - val_sparse_categorical_accuracy: 0.9568 - learning_rate: 2.0000e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 36/36\n",
      "\u001b[1m856/856\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9573 - learning_rate: 2.0000e-05\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2736 - sparse_categorical_accuracy: 0.9221\n",
      "Test loss: 0.2629866600036621\n",
      "Test accuracy: 0.9188138842582703\n"
     ]
    }
   ],
   "source": [
    "# 生成 kws_model.h5\n",
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:14:55.315553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733904895.330944  146203 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733904895.335383  146203 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 16:14:55.350467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Converting trained model trained_models/kws_model.h5 to TFL model at trained_models/kws_model.tflite\n",
      "I0000 00:00:1733904897.363757  146203 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21471 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:0b:00.0, compute capability: 7.5\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved artifact at '/tmp/tmpjh835ncs'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 49, 10, 1), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 12), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129093381787280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381788624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381790160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381787664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381790352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381792080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381792656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381794384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381794576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381797264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381797072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382324688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382327376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382329296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382329680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382331984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382335248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1733904899.720357  146203 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1733904899.720403  146203 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-11 16:14:59.720922: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpjh835ncs\n",
      "2024-12-11 16:14:59.723420: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-11 16:14:59.723456: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpjh835ncs\n",
      "I0000 00:00:1733904899.746289  146203 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2024-12-11 16:14:59.750123: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-11 16:14:59.880327: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpjh835ncs\n",
      "2024-12-11 16:14:59.922097: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 201178 microseconds.\n",
      "2024-12-11 16:14:59.965965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Wrote 45544 / 45544 bytes to tflite file\n",
      "2024-12-11 16:15:00.352219: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2024-12-11 16:15:01.529283: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-12-11 16:15:02.856811: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Cal set has 10 of label 0\n",
      "Cal set has 10 of label 1\n",
      "Cal set has 10 of label 2\n",
      "Cal set has 10 of label 3\n",
      "Cal set has 10 of label 4\n",
      "Cal set has 10 of label 5\n",
      "Cal set has 10 of label 6\n",
      "Cal set has 10 of label 7\n",
      "Cal set has 10 of label 8\n",
      "Cal set has 10 of label 9\n",
      "Cal set has 10 of label 10\n",
      "Cal set has 10 of label 11\n",
      "Saved artifact at '/tmp/tmpdx07sffy'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 49, 10, 1), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 12), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129093381787280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381788624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381790160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381787664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381790352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381792080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381791312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381792656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381794384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381789200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381794576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381793040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381797264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381796304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381797072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381798416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093381799376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382324688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382325264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382326608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382327376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382329296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382328912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382329680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382331984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382330064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382332176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129093382335248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "/home/kycho/tiny/.MLPerf311-train/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1733904904.076795  146203 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1733904904.076827  146203 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-12-11 16:15:04.076989: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdx07sffy\n",
      "2024-12-11 16:15:04.079297: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-11 16:15:04.079341: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpdx07sffy\n",
      "2024-12-11 16:15:04.104187: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-11 16:15:04.234945: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpdx07sffy\n",
      "2024-12-11 16:15:04.275237: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 198249 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n",
      "Wrote 47536 / 47536 bytes to tflite file\n"
     ]
    }
   ],
   "source": [
    "# 生成 kws_model.tflite 以及 kws_model_float32.tflite\n",
    "!python3 quantize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 656\n",
      "-rw-r--r-- 1 kycho gpu-user  47536 Dec 11 16:15 kws_model.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user  45544 Dec 11 16:15 kws_model_float32.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user 454912 Dec 11 16:01 kws_model.h5\n",
      "-rw-r--r-- 1 kycho gpu-user  43392 Dec 11 12:05 kws_ref_model_float32.tflite\n",
      "drwxr-xr-x 3 kycho gpu-user   4096 Dec 11 12:05 kws_ref_model\n",
      "-rw-r--r-- 1 kycho gpu-user  53936 Dec 11 12:05 kws_ref_model.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user    556 Dec 11 12:05 README.md\n",
      "-rw-r--r-- 1 kycho gpu-user     55 Dec 11 12:05 kws_ref_model.md5\n"
     ]
    }
   ],
   "source": [
    "!ls -lt trained_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:25:42.110431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733905542.125500  147834 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733905542.129770  147834 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 16:25:42.144622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1733905544.283715  147834 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21471 MB memory:  -> device: 0, name: Quadro RTX 6000, pci bus id: 0000:0b:00.0, compute capability: 7.5\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Evaluating on the test set\n",
      "2024-12-11 16:25:45.716487: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2024-12-11 16:25:48.543413: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "Accuracy on test = 0.920 (4497/4890)\n"
     ]
    }
   ],
   "source": [
    "# 生成 kws_model.tflite and kws_model_float32.tflite\n",
    "!python3 eval_quantized_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 656\n",
      "-rw-r--r-- 1 kycho gpu-user  47536 Dec 11 16:15 kws_model.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user  45544 Dec 11 16:15 kws_model_float32.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user 454912 Dec 11 16:01 kws_model.h5\n",
      "-rw-r--r-- 1 kycho gpu-user  43392 Dec 11 12:05 kws_ref_model_float32.tflite\n",
      "drwxr-xr-x 3 kycho gpu-user   4096 Dec 11 12:05 kws_ref_model\n",
      "-rw-r--r-- 1 kycho gpu-user  53936 Dec 11 12:05 kws_ref_model.tflite\n",
      "-rw-r--r-- 1 kycho gpu-user    556 Dec 11 12:05 README.md\n",
      "-rw-r--r-- 1 kycho gpu-user     55 Dec 11 12:05 kws_ref_model.md5\n"
     ]
    }
   ],
   "source": [
    "!ls -lt trained_models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把\n",
    "```\n",
    "sed -i .bak '1 s/^/#include \"kws_model_data.h\"\\n\\n/'  kws_model_data.cc\n",
    "sed -i .bak 's/unsigned char/const unsigned char/' kws_model_data.cc\n",
    "sed -i .bak \"s/$FNAME_CONV/g_kws_model_data/\" kws_model_data.cc\n",
    "sed -i .bak 's/unsigned int/const unsigned int/' kws_model_data.cc\n",
    "```\n",
    "改成\n",
    "```\n",
    "sed -i '1 s/^/#include \"kws_model_data.h\"\\n\\n/'  kws_model_data.cc\n",
    "sed -i 's/unsigned char/const unsigned char/' kws_model_data.cc\n",
    "sed -i \"s/$FNAME_CONV/g_kws_model_data/\" kws_model_data.cc\n",
    "sed -i 's/unsigned int/const unsigned int/' kws_model_data.cc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting file trained_models/kws_model.tflite to file kws_model_data.cc\n"
     ]
    }
   ],
   "source": [
    "# Convert to C++ Code\n",
    "!./tflm2cc trained_models/kws_model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 468\n",
      "-rw-r--r-- 1 kycho gpu-user  58105 Dec 11 16:36 __0.ipynb\n",
      "-rw-r--r-- 1 kycho gpu-user 293263 Dec 11 16:36 kws_model_data.cc\n",
      "-rwxr-xr-x 1 kycho gpu-user    850 Dec 11 16:35 tflm2cc\n",
      "-rw-r--r-- 1 kycho gpu-user    119 Dec 11 16:26 __1.ipynb\n",
      "drwxr-xr-x 3 kycho gpu-user   4096 Dec 11 16:15 trained_models\n",
      "drwxr-xr-x 2 kycho gpu-user   4096 Dec 11 16:01 plots\n",
      "drwxr-xr-x 2 kycho gpu-user   4096 Dec 11 15:53 __pycache__\n",
      "-rw-r--r-- 1 kycho gpu-user   9117 Dec 11 15:53 keras_model.py\n",
      "-rw-r--r-- 1 kycho gpu-user   4701 Dec 11 12:05 README.md\n",
      "-rw-r--r-- 1 kycho gpu-user    401 Dec 11 12:05 build_ref.sh\n",
      "-rw-r--r-- 1 kycho gpu-user   8694 Dec 11 12:05 eval_functions_eembc.py\n",
      "-rw-r--r-- 1 kycho gpu-user   2654 Dec 11 12:05 eval_quantized_model.py\n",
      "-rw-r--r-- 1 kycho gpu-user   1949 Dec 11 12:05 evaluate.py\n",
      "-rw-r--r-- 1 kycho gpu-user  15447 Dec 11 12:05 get_dataset.py\n",
      "-rw-r--r-- 1 kycho gpu-user   6374 Dec 11 12:05 kws_util.py\n",
      "-rw-r--r-- 1 kycho gpu-user    503 Dec 11 12:05 make_all_bin_files.sh\n",
      "-rw-r--r-- 1 kycho gpu-user   5691 Dec 11 12:05 make_bin_files.py\n",
      "-rw-r--r-- 1 kycho gpu-user    426 Dec 11 12:05 make_model_c_file\n",
      "-rw-r--r-- 1 kycho gpu-user   1309 Dec 11 12:05 mk_cal_set.py\n",
      "-rw-r--r-- 1 kycho gpu-user    584 Dec 11 12:05 quant_cal_idxs.txt\n",
      "-rw-r--r-- 1 kycho gpu-user   2193 Dec 11 12:05 quantize.py\n",
      "-rw-r--r-- 1 kycho gpu-user   1634 Dec 11 12:05 train.py\n"
     ]
    }
   ],
   "source": [
    "# 生成 kws_model_data.cc\n",
    "!ls -lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv kws_model_data.cc ../../reference_submissions/keyword_spotting/kws/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".MLPerf311-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
